# Prism 実ユーザーテスト計画書

**作成日**: 2026年1月11日  
**ステータス**: 計画中  
**フェーズ**: E-2（価値検証 - 実ユーザーテスト）

---

## 1. テスト目的

PoCとして実装完了したPrismが、以下の観点で「使える」かを検証する：

1. **実用性**: 想定ユースケースで実際に使えるか
2. **価値**: 既存の作業（Excel、手作業）よりも楽になるか
3. **収益化可能性**: お金を払ってでも使いたいと思えるか

---

## 2. 想定ユーザー（RDより）

### ペルソナA: データ販売者（個人事業主）
- **職業**: フリーランスのデータ収集・分析者
- **課題**: スクレイピングしたCSVを手作業で集計・レポート化している
- **期待**: 分析コメントを自動生成して納品時間を短縮したい
- **プラットフォーム**: ココナラ、ランサーズで受注

### ペルソナB: せどり実践者（副業）
- **職業**: 会社員（副業でせどり）
- **課題**: Amazon/メルカリの価格差を見つけるのに時間がかかる
- **期待**: 異常値や急変トレンドを素早く把握したい
- **利用頻度**: 週2-3回、夜間や週末

### ペルソナC: 不動産・中古車ウォッチャー
- **職業**: 投資家、事業探索者
- **課題**: 定期スクレイピングしているが、変化に気づきにくい
- **期待**: 前回データとの比較、異常値の自動検知
- **利用頻度**: 月次または週次

---

## 3. テスト参加者の募集計画

### 3.1 自分自身でのテスト（必須）

**期間**: 1週間（2026年1月中旬予定）

**実施内容**:
- 実際の業務データ（匿名化）で毎日使ってみる
- 以下のユースケースを実際に試す：
  - スクレイピング結果の集計・分析
  - クライアントへの納品レポート作成（想定）
  - 価格差・トレンド変化の検知

**記録項目**:
- 操作ログ（どの画面をどの順で使ったか）
- 不便だった点（箇条書き）
- 欲しい機能（優先度付き）
- 実際にかかった時間 vs 従来の手作業との比較

### 3.2 外部テストユーザーの募集（任意）

**目標人数**: 2-3名

**募集方法**:
- [ ] 既存の知人・同業者へ個別に依頼
- [ ] TwitterでPoC募集（スクレイピング/データ分析タグ）
- [ ] ココナラ出品者へDM（データ分析カテゴリ）

**参加条件**:
- スクレイピングまたはCSV分析の経験がある
- フィードバックを文章で提供できる
- 1-2時間のテスト時間を確保できる

**謝礼**:
- [ ] 検討中（Amazonギフト券 1,000円程度？）

---

## 4. テストシナリオ

### シナリオ1: データ販売者の納品業務（ペルソナA向け）

**前提条件**:
- Playwrightでスクレイピングした求人データCSV（100-500行程度）
- クライアントへ分析レポートを納品する想定

**テスト手順**:
1. CSVファイルをPrismにアップロード
2. 統計情報を確認（数値カラムの分布、頻出カテゴリ）
3. LLM分析結果を確認
4. 分析結果をコピーして、簡易レポートを作成（メモ帳/Wordなど）
5. グラフをスクリーンショット取得

**成功基準**:
- アップロードから分析結果確認まで **3分以内**
- 分析コメントが「そのまま使える」または「軽微な修正で使える」
- エラーやフリーズが発生しない

**観察ポイント**:
- どの機能を最初に使うか
- 統計情報とLLM分析、どちらを重視するか
- エクスポート機能があったら使うか

---

### シナリオ2: せどり実践者の価格差分析（ペルソナB向け）

**前提条件**:
- Amazon/メルカリから取得した商品価格データCSV（50-200行程度）
- 商品名、カテゴリ、価格、出品日などを含む

**テスト手順**:
1. CSVファイルをPrismにアップロード
2. 価格カラムの統計情報を確認（min/max/avg）
3. 異常値（極端に安い/高い商品）を探す
4. カテゴリ別の傾向をLLM分析から読み取る
5. 次のアクション（仕入れ判断）に繋がる情報が得られたか評価

**成功基準**:
- **高速性**: アップロードから結果確認まで **2分以内**
- **発見性**: 異常値や注目すべき商品を見つけられる
- **実用性**: 実際の仕入れ判断に使えると感じる

**観察ポイント**:
- 統計情報のどの指標を見るか（min/max/avg/頻出値）
- グラフが役立つか
- 「前回データとの比較」機能が欲しいか

---

### シナリオ3: 定期スクレイピングデータの変化検知（ペルソナC向け）

**前提条件**:
- 不動産または中古車の定期スクレイピングデータ（複数回分）
- 前回データと今回データをそれぞれアップロード

**テスト手順**:
1. 前回データ（例：1週間前）をアップロード → 統計確認
2. 今回データ（最新）をアップロード → 統計確認
3. 2つの統計情報を見比べて変化を把握
4. LLM分析から「変化」や「トレンド」が読み取れるか確認

**成功基準**:
- 2つのデータセットの比較が **5分以内** で完了
- 平均価格の変化、新規カテゴリの出現などを把握できる
- （現状は手動比較だが）自動比較機能の必要性を判断できる

**観察ポイント**:
- 手動比較でストレスを感じるか
- 「複数データセット比較」機能が強く求められるか
- どの統計指標の変化に注目するか

---

## 5. フィードバック収集方法

### 5.1 定量データ

**自動収集（実装不要、手動記録でOK）**:
- アップロードしたCSVのサイズ・行数
- 各画面の表示時間（体感で記録）
- エラー発生回数

**アンケート（Google Forms等）**:
- 満足度（5段階評価）
  - 全体的な満足度
  - 操作のしやすさ
  - 統計情報の有用性
  - LLM分析の品質
  - 表示速度
- タスク完了度（できた/できなかった/一部できた）

### 5.2 定性データ

**半構造化インタビュー（15-30分）**:

#### 基本質問
1. どのような業務でスクレイピング/CSV分析をしていますか？
2. 現在はどのツール（Excel、Python、BIツール等）を使っていますか？
3. Prismを使ってみて、最も便利だと感じた機能は何ですか？
4. 最も不便だと感じた点は何ですか？
5. この機能があれば使いたい、と思うものはありますか？

#### 価値検証の質問
6. Prismは、従来の方法と比べて時間短縮になりましたか？（何分→何分）
7. 分析の質（気づき、洞察）は向上しましたか？
8. 実際の業務で使い続けたいと思いますか？

#### 収益化の質問（重要）
9. もしPrismが有料サービスだとしたら、いくらまで払えますか？
   - 無料でないと使わない
   - 月額500円程度なら
   - 月額1,000-2,000円程度なら
   - 月額5,000円以上でも（理由を添えて）
10. どのような課金形態が望ましいですか？
    - 月額定額
    - 分析回数ごと
    - データ量ごと
    - 買い切り

#### 自由記述
11. その他、自由にご意見をお聞かせください

---

## 6. テスト環境

### 6.1 環境の選択

**案A: ローカル環境を共有（Docker Compose）**
- メリット: インフラコスト0円、データが外部に出ない
- デメリット: Docker環境のセットアップが必要、テストユーザーの負担大

**案B: クラウドにデプロイ（Render/Heroku/AWS等）**
- メリット: URLを共有するだけ、テストユーザーの負担小
- デメリット: インフラコスト発生、セキュリティ設定が必要

**決定**: 
- [ ] 自分自身のテスト → **ローカル環境**（開発環境そのまま）
- [ ] 外部テストユーザー → **クラウドデプロイ**（Render無料プラン or AWS無料枠を検討）

### 6.2 テストデータの準備

**サンプルCSVの用意**:
- [ ] 求人データ（100行程度、匿名化済み）
- [ ] 商品価格データ（50行程度、架空データ）
- [ ] 不動産データ（100行程度、公開情報のみ）

**テストユーザーへの提供**:
- 自分のデータを使ってもらう（推奨）
- サンプルCSVを提供する（データがない場合）

---

## 7. テストスケジュール

### Week 1: 準備（1月第2週）
- [ ] テスト計画の確定（本ドキュメント）
- [ ] テスト環境の決定（ローカル or クラウド）
- [ ] サンプルCSVの準備
- [ ] アンケートフォームの作成
- [ ] （外部テストする場合）参加者募集開始

### Week 2: 自分自身でのテスト（1月第3週）
- [ ] 1週間、実際の業務データで使い込む
- [ ] 不便な点、欲しい機能をメモ
- [ ] 従来手法との時間比較を記録
- [ ] 初期フィードバックをまとめる

### Week 3-4: 外部テストユーザーテスト（1月第4週〜）
- [ ] （実施する場合）環境セットアップ
- [ ] テストユーザーへの説明・依頼
- [ ] テスト実施（1人あたり1-2時間）
- [ ] インタビュー実施（1人あたり15-30分）
- [ ] フィードバック収集

### Week 5: 結果分析・判断（2月第1週）
- [ ] 定量・定性データの整理
- [ ] 優先度付け（Must / Should / Nice to have）
- [ ] Go/No-Go判断
- [ ] 次フェーズ（F）のスコープ確定

---

## 8. 成功基準（Go/No-Go判断）

### Goの基準（本格開発へ進む）

以下の **3つ以上** を満たす場合、フェーズFへ進む：

1. **満足度**: 総合満足度が5段階評価で **平均4.0以上**
2. **時間短縮**: 従来手法と比べて **30%以上の時間短縮** を実感
3. **継続利用意向**: テストユーザーの **50%以上が「使い続けたい」**
4. **支払い意向**: テストユーザーの **50%以上が「月額500円以上なら払える」**
5. **技術的成立**: 大きな技術的問題（パフォーマンス、バグ等）がない

### Pivotの基準（方向転換）

以下のような場合、ターゲット顧客や機能を見直す：

- 統計情報は好評だが、LLM分析が不要と判断される → LLMなしの軽量版を検討
- ペルソナAは刺さらないが、ペルソナBには刺さる → ターゲットを絞る
- 単発利用は良いが、継続利用は不要 → サブスクではなく従量課金を検討

### No-Goの基準（中止）

以下の場合、PoC止まりとし、知見を次に活かす：

- 総合満足度が **3.0未満**
- 「これなら手作業の方が良い」という意見が多数
- 支払い意向が **全員0円**
- 技術的に解決困難な問題が多発

---

## 9. リスクと対策

### リスク1: テストユーザーが集まらない
- **対策**: まずは自分自身での1週間テストで十分な知見を得る
- **代替案**: 1名だけでも外部テストできれば実施

### リスク2: テスト環境のトラブル（クラウドデプロイの場合）
- **対策**: 事前に自分でE2Eテスト、スクリーンショット手順書を用意
- **代替案**: Loomで画面録画を共有し、ローカル環境でのセットアップをサポート

### リスク3: 機密データの扱い
- **対策**: テストユーザーには「匿名化データ推奨」を明記
- **対策**: サンプルCSVを提供し、自分のデータを使わなくても良い選択肢を用意

### リスク4: フィードバックが抽象的で判断材料にならない
- **対策**: インタビューで具体的な事例を深掘りする質問を用意
- **対策**: 「どのシーンで使いたいか」「何分短縮できそうか」を数値で聞く

---

## 10. 次アクション（チェックリスト）

### 今すぐやること
- [ ] 本計画書をレビューし、過不足を確認
- [ ] テスト環境（ローカル or クラウド）を決定
- [ ] サンプルCSVを3種類準備
- [ ] アンケートフォームを作成（Google Forms）

### 今週中にやること（Week 1）
- [ ] 自分自身での1週間テストを開始
- [ ] （外部テストする場合）参加者募集の文面を作成
- [ ] （クラウドデプロイする場合）デプロイ先を選定・初回デプロイ

### 来週以降
- [ ] テスト実施 → フィードバック収集 → 結果分析 → Go/No-Go判断

---

## 11. 参考資料

- `docs/Requirements Definition.md` - 想定ユーザー・ユースケース
- `docs/develop_process.md` - フェーズE全体の流れ
- `README.md` - PoCの範囲と制約

---

**このドキュメントは生きたドキュメントです。テスト実施中に気づいたことがあれば随時更新してください。**
