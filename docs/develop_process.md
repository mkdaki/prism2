# Prism PoC 実装タスクチェックリスト

（2026/01/09 更新）

## 開発方針：ローカル環境を汚さない（テストはコンテナ内で完結）

本プロジェクトは Windows11 + Docker Desktop を前提とし、ローカルPCのPython環境（グローバル/venv）を汚さない方針とする。

- Python依存関係の導入・更新は backend コンテナ内でのみ行う
- テスト（pytest等）は backend コンテナ内でのみ実行する
- CI も「コンテナで実行するテスト手順」を基準に整備し、ローカル/CIで結果がズレないようにする

目的：

- 環境差分による不具合（依存関係・バージョン差異）を最小化する
- 参画者が増えても再現性の高い開発手順を維持する

## フェーズA：PoCを「操作可能」にする必須タスク

### A-0. 品質・土台（先に整備）

* [x] A-0-1. CORS を設定
  
  * [x] 例：`http://localhost:3001` を許可
  * [x] 許可オリジンは環境変数で切替できるようにする

* [x] A-0-2. テスト基盤を追加
  
  * [x] `pytest` / FastAPI TestClient
  * [x] カバレッジ計測（80%以上を維持）
  * [x] テストは backend コンテナ内で実行する（ローカルPCへpytest等を導入しない）

* [x] A-0-3. CI を追加
  
  * [x] Backend：テスト + coverage 80%以上
  * [x] Frontend：build を実行

* [x] A-0-4. Alembic 方針決定
  
  * [x] Alembic を導入し、起動時 `create_all` 依存を解消する方針を決める
  * [x] フェーズAでは「方針決定」まででも可（導入作業はフェーズBに寄せても良い）

#### A-0-4. Alembic 方針決定（決定事項）

- DBスキーマ管理は Alembic を正式採用する。
- フェーズAでは Alembic を導入せず、フェーズB-0で初期マイグレーションを作成する。
- フェーズB-0以降は Alembic を DB スキーマ管理の唯一の正とする。
- それに伴い、起動時の `Base.metadata.create_all(...)` は B-0 完了時に削除し、
  DB 作成・更新は `alembic upgrade head` に統一する。

---

### A-1. データセット一覧取得 API

* [x] `GET /datasets` エンドポイントを実装

* [x] `datasets` テーブルから一覧取得

* [x] 各 dataset について以下を返却
  
  * [x] dataset_id
  * [x] filename
  * [x] created_at
  * [x] 行数（`dataset_rows` の COUNT）

* [x] レスポンス形式を JSON として確定

* [x] Swagger（/docs）で確認

* [x] ユニットテストを追加（正常系：0件/複数件、行数COUNTが返ること）

---

### A-2. データセット詳細取得 API

* [x] `GET /datasets/{dataset_id}` を実装

* [x] 指定 dataset_id の存在チェック

* [x] 以下の情報を返却
  
  * [x] メタ情報（filename / created_at）
  * [x] 行数
  * [x] JSONB データのサンプル（先頭 N 行）

* [x] サンプル件数を固定値（例：10件）にする

* [x] エラー時のレスポンスを定義（404 等）

* [x] ユニットテストを追加（正常系、異常系：存在しないIDで404）

---

### A-3. フロントエンド：CSVアップロード機能

* [x] CSVアップロード用画面を作成
* [x] `<input type="file">` を配置
* [x] `POST /datasets/upload` を呼び出す処理を実装
* [x] 成功時レスポンス（dataset_id / 行数）を画面表示
* [x] エラー時の最低限の表示（alert 等）
* [x] ユニットテストを追加（少なくともAPI呼び出し処理を関数化してテスト）

#### A-3. フロントエンドテスト方針（決定事項）

- A-3実施時点で、フロントのユニットテスト基盤を**最小構成で導入**する（例：Vitest）。
- 対象はまず「API呼び出し処理」を関数化した部分とし、HTTPリクエストの成功/失敗時の整形・例外処理をテストする。
- テスト拡張（レンダリングテスト等）はフェーズC-0で実施範囲を再検討する。

---

## フェーズB：分析 PoC としての中核機能

### B-0. 品質・土台（分析機能の前に）

* [x] Alembic を導入し、初期マイグレーションを作成（`datasets` / `dataset_rows`）
* [x] 起動時の `create_all` を削除（DBスキーマはマイグレーションで管理）
* [x] CI にマイグレーション適用（例：テストDBに `alembic upgrade head`）を組み込む

#### B-0 補足：開発用DBとテスト用DBを分離する（推奨）

pytest はテストの独立性のため、テスト後に対象テーブルを TRUNCATE します。
開発用DBのデータ永続化（本番相当データでの検証）と両立するため、Composeプロジェクト名を分けてテスト専用DBを使います。

```bash
# テスト用DBを起動（開発用とは別のボリューム/ネットワーク）
docker compose -p prism2-test up -d db

# backend のソースを変更している場合は、テスト前に必ず再ビルドする（COPY型のため）
# ※ build を省略すると「古いイメージ」でpytestが走り、結果（テスト数/カバレッジ）がズレます
docker compose -p prism2-test build backend

# スキーマ適用（entrypointの自動migrationはOFFにして明示的に）
docker compose -p prism2-test run --rm -e RUN_MIGRATIONS=0 backend alembic upgrade head

# テスト実行
docker compose -p prism2-test run --rm -e RUN_MIGRATIONS=0 backend pytest

# 片付け（テスト用DBだけ破棄）
docker compose -p prism2-test down -v
```

---

### B-1. 最小集計（統計）API

* [x] `GET /datasets/{dataset_id}/stats` を実装

* [x] 対象 dataset の行数を算出

* [x] JSONB からカラム一覧を抽出

* [x] 数値カラムについて以下を算出（可能な範囲で）
  
  * [x] min
  * [x] max
  * [x] avg

* [x] 集計結果を JSON で返却

* [x] 計算不可カラムは除外（PoC割り切り）

* [x] 文字列カラムも要約対象に含める（例：案件名）
  
  * [x] カラムごとに kind（`number` / `string` / `mixed` / `empty`）を返す
  * [x] `string` / `mixed` は上位頻出値（top values）を返す

* [x] ユニットテストを追加（数値/非数値/欠損の混在を含む最低限のパターン）

#### B-1 レスポンス例（参考）

以下は `GET /datasets/{dataset_id}/stats` のレスポンス例です（例示のため一部省略）。

```json
{
  "dataset_id": 1,
  "rows": 4,
  "columns": [
    {
      "name": "project",
      "kind": "string",
      "present_count": 4,
      "non_empty_count": 3,
      "numeric": null,
      "top_values": [
        { "value": "案件A", "count": 2 },
        { "value": "案件B", "count": 1 }
      ]
    },
    {
      "name": "amount",
      "kind": "number",
      "present_count": 4,
      "non_empty_count": 3,
      "numeric": { "count": 3, "min": 100.0, "max": 300.0, "avg": 200.0 },
      "top_values": null
    },
    {
      "name": "mixed",
      "kind": "mixed",
      "present_count": 4,
      "non_empty_count": 4,
      "numeric": { "count": 3, "min": 1.0, "max": 3.0, "avg": 2.0 },
      "top_values": [{ "value": "x", "count": 1 }]
    },
    {
      "name": "empty",
      "kind": "empty",
      "present_count": 4,
      "non_empty_count": 0,
      "numeric": null,
      "top_values": null
    }
  ]
}
```

---

### B-2. LLM 簡易分析 API

目的：B-1 の集計結果を入力として、LLM で「注目点 / 仮説」を生成し API で返す（PoC割り切りで保存しない）。

#### B-2 方針（決めること）

* [x] 利用する LLM の方式を決定（**Gemini API** を利用）
* [ ] 機密/個人情報の扱い方針を決定
  * [ ] 原則：**行データは送らない**（B-1 stats など要約のみ送る）
  * [ ] カラム名/頻出値に機微が含まれる可能性があるため、送信前にマスク/制限するかを決める
* [x] タイムアウト/失敗時の API 方針を決定（例：503/504、リトライ有無）
* [ ] コスト/速度の上限を決める（例：最大トークン、stats の入力サイズ上限）

#### B-2-0. 最小の土台（LLM なしで形を固める）

* [x] `GET /datasets/{dataset_id}/analysis` を追加
* [x] 内部で B-1 の集計結果を取得できるようにする（処理の共有/再利用）
* [x] 返却 JSON の形を確定（例：`dataset_id` / `generated_at` / `analysis_text`）
* [x] まずは固定文言 + stats の要点だけでレスポンスが返る（LLM未接続でもUIが作れる状態）
* [x] ユニットテスト：正常系（存在する dataset_id）、異常系（存在しない dataset_id は 404）

#### B-2-1. LLM クライアントの抽象化（テスト容易性）

* [x] LLM 呼び出しをラップするインターフェースを作る（実装差し替え可能に）
* [x] 環境変数で API Key / モデル名 / タイムアウト等を切替できるようにする
* [x] ユニットテスト：LLM 部分はスタブ/モックで差し替え可能であること

#### B-2-2. プロンプト v1（品質より再現性を優先）

* [x] プロンプトをコード内に定義（テンプレート化）
* [x] 出力フォーマットを指示（見出し付き箇条書き、過度な断定を避ける、前提と限界を明記）
* [x] stats の入力を必要最小限に圧縮（列一覧/数値統計/上位頻出値など）
* [x] ユニットテスト：プロンプト組み立てが期待通り（stats が埋め込まれる、サイズ上限が効く）

補足（初期パラメータ / v1 方針）：

- **max_columns=30**
- **max_top_values_per_column=3**
- **max_prompt_chars=9000**
- サイズ上限超過時は段階的に省略（まず top_values を落とす → 列数を絞る → 最低限の概要に落とす）

#### B-2-3. エラーハンドリング（PoCでも最低限）

* [x] LLM 失敗時の扱いを実装（タイムアウト、認証エラー、上限超過など）
* [x] API レスポンス（ステータス/メッセージ）を確定
* [x] ユニットテスト：LLM 例外時に期待ステータス/レスポンスになる

#### B-2-4. 代表 CSV での手動評価（品質チューニングの入口）

* [x] 代表データ（想定利用に近い CSV）で B-1 stats → B-2 出力を確認し、改善点をメモする
  * 例：Playwright スクレイピング結果の列を含む CSV
  * 注意：**機密/個人情報が含まれる場合はコミットしない**（匿名化したサンプルのみリポジトリに入れる）
  * 代表CSVの置き場所：`samples/playwright_scrape_sample.csv`（必要に応じて更新）
  * 手順（最小）：
    * [x] CSV をアップロードして dataset_id を得る
    * [x] `GET /datasets/{dataset_id}/stats` を確認（入力が想定通りか）
    * [x] `GET /datasets/{dataset_id}/analysis` を確認（出力の妥当性/言い回し/過度な断定がないか）
    * [x] 改善点をメモし、B-2-2 のプロンプトと B-2-3 のエラーハンドリングへ反映する

メモ（代表CSVでの確認結果 / 改善点）：

- `CategoryText` の上位値に不自然な空白混入（例：`IT・通信・インターネ ット`）が見られた。
  - 対応案：CSV取り込み時または集計前に、連続空白の圧縮・全角/半角スペース正規化を検討。
- LLM出力の見出しが崩れるケース（例：`## 前 提・限界` のようにスペースが混入）が見られた。
  - 対応案：プロンプトに「見出しはスペースを入れず、指定の文言を完全一致で出力」と追記することを検討。

#### B-2-5. 実LLMプロバイダ導入（Gemini）＋疎通確認

目的：`GET /datasets/{dataset_id}/analysis` が **実際に Gemini API を呼び出して**分析テキストを返せる状態にする（PoC割り切りで保存しない）。

* [x] Gemini の利用方式を確定（**Google AI Studio（API Key方式）** を利用）
* [x] 利用モデル名を確定（デフォルト：`gemini-1.5-flash`、必要に応じて変更）
* [x] Backend に Gemini クライアント実装を追加（`LLM_PROVIDER=gemini` で選択できるように）
* [x] Backend の環境変数を確定・Compose に反映（例：`LLM_PROVIDER` / `LLM_API_KEY` / `LLM_MODEL` / `LLM_TIMEOUT_SECONDS`）
  * [x] **APIキーはコミットしない**（`.env` / CI secret / ローカル設定で注入）
  * [x] ローカル用サンプル：`docs/env.example` をリポジトリルートの `.env` にコピーして編集する
* [x] 動作確認手順を確定（コンテナ内で実行）
  * [x] `ANALYSIS_USE_LLM=1` を有効化して `/analysis` を叩く
  * [x] 代表CSVで `stats → analysis` が一連で動くことを確認（必要なら B-2-4 と統合してOK）
* [x] 失敗時の挙動が B-2-3 の仕様どおりであることを確認（タイムアウト/認証/上限など）
* [x] テスト方針を確定（ユニットテストはモック継続、疎通は手動/任意のintegrationに分離）

#### B-2-5 確認結果（2026/01/10）

**テスト実行結果:**
- 全29テスト通過（test_gemini_client.py 8件、test_dataset_analysis.py 4件を含む）
- カバレッジ: 89.55%（目標80%以上を達成）

**確認済みエラーハンドリング:**

1. **LLMエラークラス定義** (`app/llm.py`)
   - `LLMTimeoutError` → 504 Gateway Timeout (retryable)
   - `LLMAuthError` → 503 Service Unavailable (non-retryable)
   - `LLMRateLimitError` → 503 Service Unavailable (retryable)
   - `LLMInputTooLargeError` → 413 Payload Too Large (non-retryable)
   - `LLMProviderError` → 502 Bad Gateway (retryable)

2. **Geminiクライアントでのマッピング** (`app/llm.py` lines 140-198)
   - HTTP 401/403 → `LLMAuthError`
   - HTTP 429 → `LLMRateLimitError`
   - HTTP 413 / 400(message含む) → `LLMInputTooLargeError`
   - HTTP 500-599 → `LLMProviderError`
   - `httpx.TimeoutException` → `LLMTimeoutError`

3. **APIエンドポイントでのエラーレスポンス** (`app/main.py` lines 279-304)
   - エラーレスポンス形式: `{"error": {"code": "...", "message": "...", "retryable": true/false}}`
   - 各LLMエラーが適切なHTTPステータスにマップされることを確認

**テスト実行手順:**
```bash
# テスト用DBを起動
docker compose -p prism2-test up -d db

# Backendをビルド
docker compose -p prism2-test build backend

# スキーマ適用
docker compose -p prism2-test run --rm -e RUN_MIGRATIONS=0 backend alembic upgrade head

# テスト実行
docker compose -p prism2-test run --rm -e RUN_MIGRATIONS=0 backend pytest -v --cov=app

# クリーンアップ
docker compose -p prism2-test down -v
```

#### B-2 Done（最小）

* [x] `GET /datasets/{dataset_id}/analysis` が Swagger で確認できる
* [x] stats を入力にしたテキストが返り、失敗時の挙動（ステータス/メッセージ）が決まっている
* [x] テストがあり、LLM 呼び出し部分はモックで検証できる

---

## フェーズC：管理画面として最低限成立させる

### C-0. 品質・土台（画面機能の前に）

* [x] フロントのCIを整備（`npm ci` → `npm run build`）
* [x] フロントの簡易テスト導入（最低限のレンダリング/ロジックのテスト。テスト方式はここで確定）

#### C-0 決定事項（テスト方式メモ）

- ユニットテストは **Vitest** を採用し、`frontend` で `npm test`（=`vitest run`）として実行する。
- 当面の対象は **ロジック/API呼び出し（例：`src/api/*`）** を優先する（ブラウザ依存はモック/スタブで吸収）。
- CI では `frontend-build` ジョブで `npm ci` → `npm test` → `npm run build` を実行し、失敗時はPRを落とす。
- Reactコンポーネントのレンダリングテスト（Testing Library / jsdom 等）は、C-1/C-2の画面実装が進んだ段階で必要最小限を追加する。

---

### C-1. データセット一覧画面

* [x] 起動時に `GET /datasets` を呼び出す
* [x] データセット一覧をテーブル表示
* [x] dataset_id をクリック可能にする
* [x] 選択時に詳細画面へ遷移
* [x] ユニットテストを追加（一覧表示・エラー表示の最低限）

---

### C-2. データセット詳細・分析画面

* [x] 詳細 API（A-2）の結果を表示
* [x] 集計 API（B-1）の結果を表示
* [x] LLM 分析結果（B-2）を表示
* [x] レイアウトは最小限（装飾不要）
* [x] ユニットテストを追加（詳細取得失敗時の表示、主要コンポーネントが落ちないこと）

#### C-2 実装内容（完了）

- `frontend/src/api/datasets.ts` に3つのAPI型定義と関数を追加
  - `getDatasetDetail(datasetId)` - データセット詳細取得
  - `getDatasetStats(datasetId)` - 統計情報取得
  - `getDatasetAnalysis(datasetId)` - 分析結果取得
- `frontend/src/pages/DatasetDetailPage.tsx` を実装
  - 3つのAPIを並行で呼び出し（Promise.all）
  - メタ情報セクション（ファイル名、作成日時、行数）
  - サンプルデータテーブル（先頭10行）
  - 統計情報セクション（カラムごとの集計結果、kind別の色分け）
  - LLM分析結果セクション（テキスト表示）
  - ローディング状態とエラーハンドリング
- `frontend/src/api/datasets.test.ts` にテストを追加
  - 各API関数の正常系テスト
  - 404エラー時のテスト
  - LLMエラー時のテスト
- 動作確認（実データでの表示確認）
  - フロントエンドテスト: 12件すべて通過
  - APIエンドポイント疎通確認: 詳細/統計/分析すべて正常動作

---

### C-3. 簡易グラフ表示（任意）

* [x] グラフライブラリを 1 つ選定
* [x] 件数 or 数値分布を 1 種類表示
* [x] 見た目より「動くこと」を優先

#### C-3 実装内容（完了）

- **グラフライブラリ選定: Recharts v2.13.3**
  - 選定理由: React専用、シンプルなAPI、TypeScript対応、軽量、ドキュメント充実
  
- **実装内容:**
  - 数値カラム（kind="number"）の統計グラフ
    - 最小値、平均値、最大値を棒グラフで表示
    - 青色（#2196f3）のバーで視覚化
  - 文字列カラム（kind="string" or "mixed"）の頻出値グラフ
    - 上位頻出値を棒グラフで表示
    - 緑色（#4caf50）のバーで視覚化
  - ResponsiveContainer でレスポンシブ対応
  - ツールチップ、凡例、グリッド線を実装

- **動作確認:**
  - フロントエンドテスト: 12件すべて通過
  - コンパイルエラー: なし
  - 確認URL:
    - シンプルデータ: http://localhost:3001/datasets/5
    - 大規模データ: http://localhost:3001/datasets/3

---

## フェーズD：安定性・PoC品質の底上げ（後回し可）

* [x] CSV の文字コードエラー対策（UTF-8前提明示）
* [x] 空 CSV / 不正 CSV のエラーハンドリング
* [x] Backend ログの粒度整理
* [x] README に「PoCでやらないこと」を再明示

### D-1. CSV文字コードエラー対策（完了）

**実装内容:**
- UTF-8とShift_JIS（CP932）の自動検出と変換を追加
- フロントエンドに対応エンコーディングの注意書きを表示
- エラーメッセージを改善（具体的な対処法を提示）

**変更ファイル:**
- `backend/app/main.py`: エンコード自動検出処理を追加
- `frontend/src/pages/UploadPage.tsx`: 対応形式の注意書きを追加

**テスト:**
- `testPostDatasetsUploadAcceptsShiftJis`: Shift_JIS対応を確認

### D-2. 空CSV/不正CSVのエラーハンドリング（完了）

**実装内容:**
- 完全な空ファイルのチェックを追加
- ヘッダー行の検証（カラム名が空でないか）
- エラーメッセージの改善

**変更ファイル:**
- `backend/app/main.py`: バリデーション処理を強化

**テスト:**
- `testPostDatasetsUploadRejectsCompletelyEmptyFile`: 空ファイル拒否を確認
- `testPostDatasetsUploadRejectsEmptyColumnName`: 空カラム名拒否を確認
- `testPostDatasetsUploadRejectsEmptyCsv`: データ行なし拒否を確認（既存）

### D-3. Backendログの粒度整理（完了）

**実装内容:**
- すべてのエンドポイントにリクエスト/レスポンスログを追加
- エラー時のスタックトレース出力（`exc_info=True`）
- LLM呼び出し時のログ追加（成功時の文字数、失敗時の詳細）
- アップロード時のエンコード検出ログ

**変更ファイル:**
- `backend/app/main.py`: ロギング設定と各エンドポイントへのログ追加

**ログ出力例:**
```
2026-01-10 05:21:15 [INFO] prism.backend: POST /datasets/upload - Uploading file: sample.csv
2026-01-10 05:21:15 [INFO] prism.backend: POST /datasets/upload - Detected encoding: utf-8
2026-01-10 05:21:15 [INFO] prism.backend: POST /datasets/upload - Success: dataset_id=1, rows=2, filename=sample.csv
```

### D-4. READMEに「PoCでやらないこと」を再明示（完了）

**実装内容:**
- README.mdに「PoCの範囲と制約」セクションを追加
- 実装済み機能と意図的に実装していない機能を明示
- 本番運用に向けた推奨改善事項を列挙

**追加内容:**
- セキュリティ制約（認証・認可なし等）
- データ永続性・バックアップなし
- パフォーマンス・スケーラビリティの制限
- 運用性の不足（監視、ログローテーションなし等）
- 機密情報・プライバシー対策の不足
- LLM関連の制約（コスト制御、プロンプトインジェクション対策なし等）

**変更ファイル:**
- `README.md`: 約100行の詳細な制約説明を追加

### フェーズD完了確認（2026/01/10）

**テスト実行結果:**
```
全32テスト通過 ✓
カバレッジ: 89.26%（目標80%以上達成）
```

**新規追加テスト（3件）:**
1. `testPostDatasetsUploadRejectsCompletelyEmptyFile` - 空ファイル拒否
2. `testPostDatasetsUploadAcceptsShiftJis` - Shift_JIS対応確認
3. `testPostDatasetsUploadRejectsEmptyColumnName` - 空カラム名拒否

**変更ファイル一覧:**
- Backend: `backend/app/main.py`（エンコード検出、バリデーション、ログ追加）
- Frontend: `frontend/src/pages/UploadPage.tsx`（注意書き追加）
- テスト: `backend/tests/test_datasets_upload.py`（3件追加、1件修正）
- ドキュメント: `README.md`（PoC制約セクション追加）

---

## PoC完了チェック（Done 定義との照合）

* [x] CSV をブラウザからアップロードできる
* [x] PostgreSQL にデータが格納される
* [x] 集計結果を API で取得できる
* [x] LLM の分析コメントが生成される
* [x] すべてを画面上で確認できる

### 確認結果（2026/01/10）

#### 1. 環境起動・アクセス確認 ✓
- Backend: `http://localhost:8001` - 正常動作
- Frontend: `http://localhost:3001` - 正常動作
- Database: PostgreSQL - 正常動作

#### 2. CSV アップロード機能 ✓
- `POST /datasets/upload` でsample.csvをアップロード成功
- レスポンス: `{"dataset_id":5,"rows":2,"filename":"sample.csv"}`

#### 3. PostgreSQL へのデータ格納 ✓
- `datasets` テーブル: dataset_id=5 のレコードが正常に作成
- `dataset_rows` テーブル: 2行のJSONBデータが正常に格納
  - row_index=0: `{"colA": "1", "colB": "hello"}`
  - row_index=1: `{"colA": "2", "colB": "world"}`

#### 4. 集計結果 API ✓
- `GET /datasets` - データセット一覧取得成功（5件のデータセット）
- `GET /datasets/5` - 詳細情報取得成功（メタ情報+サンプルデータ）
- `GET /datasets/5/stats` - 統計情報取得成功
  - colA: 数値型、min=1.0、max=2.0、avg=1.5
  - colB: 文字列型、頻出値="hello"(1件)、"world"(1件)

#### 5. LLM 分析コメント生成 ✓
- `GET /datasets/5/analysis` - 分析結果取得成功（スタブモード）
- 出力形式: 注目点、仮説、追加確認事項、前提・限界の各セクション
- 統計情報を基にした適切な分析コメントが生成されている

#### 6. 画面上での総合確認 ✓
- フロントエンド（React + TypeScript）が正常に起動
- APIエンドポイントとの疎通確認完了
- 以下の画面が実装済み:
  - データセット一覧画面（C-1）
  - データセット詳細・分析画面（C-2）
  - CSVアップロード画面（A-3）

### 結論
**PoC の基本機能はすべて正常に動作しています。**

---

## フェーズE：価値検証（ユーザー視点での評価）

PoCとしての技術実装は完了したため、次は「実際に使えるか」「収益化できるか」を検証するフェーズに移行します。

### E-1. 最小限の使いやすさ改善（実ユーザーテスト前）

* [ ] E-1-1. データセット削除機能
  * [ ] `DELETE /datasets/{dataset_id}` エンドポイントを実装
  * [ ] CASCADE設定により `dataset_rows` も自動削除されることを確認
  * [ ] フロントエンドに削除ボタンを追加（一覧画面または詳細画面）
  * [ ] 削除確認ダイアログを実装（誤操作防止）
  * [ ] ユニットテストを追加（正常系、異常系：存在しないIDで404）

* [ ] E-1-2. 分析結果のコピー/エクスポート機能
  * [ ] 分析結果テキストのコピーボタンを追加（クリップボードAPI利用）
  * [ ] 分析結果のMarkdownエクスポート機能を追加
    * [ ] ファイル名：`analysis_{dataset_id}_{YYYYMMDD}.md`
    * [ ] 内容：メタ情報 + 統計サマリー + LLM分析結果
  * [ ] 統計情報のCSVエクスポート機能を追加（オプション）
  * [ ] ユニットテストを追加（エクスポート処理の検証）

* [ ] E-1-3. UI/UXの微調整（任意）
  * [ ] ローディング中の表示改善（スピナー、プログレスバー）
  * [ ] エラーメッセージの改善（ユーザーフレンドリーな文言）
  * [ ] レスポンシブデザインの確認（モバイル対応は必要か検討）

---

### E-2. 実ユーザーテスト

* [ ] E-2-1. テスト計画の策定
  * [ ] テスト対象ユーザーの選定（想定ペルソナ：Playwrightスクレイピング利用者など）
  * [ ] テストシナリオの作成
    * [ ] 典型的な業務フロー（CSV準備 → アップロード → 分析結果確認 → レポート作成）
    * [ ] エッジケース（大容量CSV、複雑なカラム構成、エラー処理）
  * [ ] フィードバック収集方法の決定（アンケート、インタビュー、画面録画）

* [ ] E-2-2. 自分自身での使い込み（1週間）
  * [ ] 実際の業務データ（匿名化）でのテスト
  * [ ] 日常的なユースケースの洗い出し
  * [ ] 不便な点、欲しい機能のリストアップ
  * [ ] パフォーマンス問題の確認（どのサイズのCSVまで現実的か）

* [ ] E-2-3. 外部ユーザーテスト（可能であれば 2-3名）
  * [ ] テストユーザーへの環境提供（ローカル or デプロイ環境）
  * [ ] 操作ガイドの準備（README補足 or 簡単なマニュアル）
  * [ ] フィードバックの収集
  * [ ] 使用ログの分析（どの機能が使われたか、エラー発生箇所）

* [ ] E-2-4. フィードバックの整理・分析
  * [ ] 定量データ（完了率、エラー率、処理時間）
  * [ ] 定性データ（満足度、改善要望、使いにくかった点）
  * [ ] 優先度付け（Must / Should / Nice to have）

---

### E-3. 収益化可能性の検証

* [ ] E-3-1. ターゲット顧客の明確化
  * [ ] 個人開発者 vs 企業チーム（どちらがメインか）
  * [ ] 業種・職種の特定（マーケター、データアナリスト、エンジニアなど）
  * [ ] 現在の課題・ペインポイントの整理

* [ ] E-3-2. 価値提案の明確化
  * [ ] 本ツールが解決する問題は何か
  * [ ] 既存の代替手段（Excel、Googleスプレッドシート、BIツール）との差別化
  * [ ] 「これがあると何時間短縮できるか」「どれだけ楽になるか」の定量化

* [ ] E-3-3. 収益モデルの検討
  * [ ] 課金対象の候補
    * [ ] 分析回数（月10回まで無料、それ以上は有料など）
    * [ ] データ量（行数、ファイルサイズ制限）
    * [ ] 高度な分析機能（カスタムプロンプト、複数データセット比較）
    * [ ] チーム機能（共有、コラボレーション）
  * [ ] 価格帯の検討
    * [ ] 個人向け：月額 $5-20 程度？
    * [ ] 企業向け：月額 $50-200 程度？
  * [ ] 競合調査（類似ツールの価格帯）

* [ ] E-3-4. 支払い意向の確認
  * [ ] テストユーザーへのヒアリング
    * [ ] 「このツールにいくらまで払えますか？」
    * [ ] 「どの機能があれば有料でも使いますか？」
  * [ ] 仮説の検証（想定価格で採算が取れるか）

---

### E-4. 次フェーズへの判断

* [ ] E-4-1. 判断基準の設定
  * [ ] テストユーザーの満足度（例：5段階評価で平均4以上）
  * [ ] 支払い意向の有無（例：3名中2名以上が「有料でも使いたい」）
  * [ ] 技術的な実現可能性（現在の実装で耐えられるか）

* [ ] E-4-2. Go/No-Go判断
  * [ ] **Go（本格開発へ）**：フェーズFの実用化機能を実装
  * [ ] **Pivot（方向転換）**：ターゲット顧客や機能を見直す
  * [ ] **No-Go（中止）**：PoC止まりとし、知見を次に活かす

* [ ] E-4-3. 判断結果の記録
  * [ ] 判断理由の明文化
  * [ ] 次フェーズのスコープ確定（フェーズFに進む場合）

---

## フェーズF：実用化のための追加機能（フェーズE後に必要に応じて実施）

**前提**：フェーズEの結果「本格開発に進む」と判断した場合のみ実施します。

### F-0. 実用化の土台（先に整備）

* [ ] F-0-1. 認証・認可の実装（最低限）
  * [ ] ユーザー登録・ログイン機能
  * [ ] データセットの所有権管理（他人のデータセットは見れない）
  * [ ] セッション管理またはJWT認証

* [ ] F-0-2. デプロイ環境の整備
  * [ ] 本番環境の選定（AWS/GCP/Azure/Heroku/Render等）
  * [ ] HTTPS対応
  * [ ] 環境変数の管理（Secrets Manager等）
  * [ ] バックアップ戦略の策定

* [ ] F-0-3. 監視・ログの整備
  * [ ] エラー通知（Sentry等）
  * [ ] メトリクス収集（レスポンスタイム、エラー率）
  * [ ] コスト監視（LLM API使用量）

---

### F-1. データ管理の改善

* [ ] F-1-1. データセットのメタ情報編集
  * [ ] データセット名の変更機能
  * [ ] 説明文の追加機能
  * [ ] タグ付け機能（検索用）

* [ ] F-1-2. 検索・フィルタリング機能
  * [ ] データセット一覧の検索（ファイル名、タグ）
  * [ ] 並び替え（作成日、ファイル名、行数）
  * [ ] ページネーション（大量データセット対応）

* [ ] F-1-3. データ保持ポリシー
  * [ ] 古いデータセットの自動削除（30日後など）
  * [ ] データ保持期限の通知

---

### F-2. 分析の高度化

* [ ] F-2-1. カスタムプロンプト機能
  * [ ] ユーザーが分析観点を指定できるようにする
    * [ ] 例：「売上に影響する要因を見つけて」
    * [ ] 例：「異常値を指摘して」
  * [ ] プロンプトテンプレートの提供（初心者向け）

* [ ] F-2-2. 分析履歴の保存
  * [ ] 同じデータセットに対する複数回の分析を保存
  * [ ] 過去の分析結果との比較
  * [ ] 分析結果へのメモ追加機能

* [ ] F-2-3. 複数データセットの比較
  * [ ] 2つ以上のデータセットを並べて比較
  * [ ] 時系列データの変化を分析

* [ ] F-2-4. グラフのカスタマイズ
  * [ ] 表示するカラムの選択
  * [ ] グラフ種類の切替（棒グラフ、折れ線グラフ、散布図）
  * [ ] グラフの画像エクスポート

---

### F-3. ワークフロー改善

* [ ] F-3-1. エクスポート機能の拡充
  * [ ] PDF形式でのレポート出力
  * [ ] Excel形式での統計情報出力
  * [ ] PowerPoint形式でのプレゼン資料生成（オプション）

* [ ] F-3-2. 共有機能
  * [ ] 分析結果の共有リンク生成（閲覧専用）
  * [ ] チームメンバーとのデータセット共有
  * [ ] コメント・レビュー機能

* [ ] F-3-3. スケジュール実行（高度）
  * [ ] 定期的なCSVアップロード（API連携）
  * [ ] 自動分析の実行
  * [ ] 結果のメール通知

---

### F-4. パフォーマンス・スケーラビリティ

* [ ] F-4-1. 大容量CSV対応
  * [ ] ストリーミング処理の導入
  * [ ] チャンク単位での読み込み・保存
  * [ ] 100MB以上のファイル対応

* [ ] F-4-2. 統計処理の最適化
  * [ ] 集計結果のキャッシュ
  * [ ] バックグラウンドジョブ化（Celery等）
  * [ ] インデックスの最適化

* [ ] F-4-3. フロントエンドの最適化
  * [ ] 仮想スクロール（大量行の表示）
  * [ ] 遅延ロード（グラフ、画像）
  * [ ] ビルドサイズの削減

---

### F-5. セキュリティ強化

* [ ] F-5-1. 入力バリデーション強化
  * [ ] CSVヘッダーの厳密な検証
  * [ ] カラム名のサニタイゼーション
  * [ ] 悪意のあるファイルの検出

* [ ] F-5-2. レート制限
  * [ ] API呼び出しの制限（1時間あたり100回など）
  * [ ] アップロードサイズの厳格化
  * [ ] LLM呼び出しの上限設定

* [ ] F-5-3. 個人情報検出
  * [ ] PII（Personally Identifiable Information）の検出
  * [ ] 機微情報を含む場合の警告表示
  * [ ] LLMへの送信前のマスキング処理

---

### F-6. 収益化機能の実装

* [ ] F-6-1. 課金システムの導入
  * [ ] Stripe等の決済システム連携
  * [ ] プラン管理（Free / Pro / Enterprise等）
  * [ ] 使用量の計測（分析回数、データ量）

* [ ] F-6-2. プラン別機能制限
  * [ ] Freeプラン：月10回まで、100MB以下
  * [ ] Proプラン：月100回まで、1GB以下、カスタムプロンプト可能
  * [ ] Enterpriseプラン：無制限、共有機能、優先サポート

* [ ] F-6-3. ユーザーダッシュボード
  * [ ] 使用量の可視化
  * [ ] プランのアップグレード/ダウングレード
  * [ ] 請求書・領収書の発行

---

## 補足：フェーズE完了後の振り返り（予定地）

フェーズEの実施後、以下を記録してください：

* [ ] テスト参加者数と属性
* [ ] 主なフィードバック（良かった点、改善点）
* [ ] 支払い意向の結果
* [ ] Go/No-Go判断の結果と理由
* [ ] フェーズFで優先する機能（実施する場合）

---
